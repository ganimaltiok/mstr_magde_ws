# Cache zones
proxy_cache_path /var/cache/nginx/shortcache 
    levels=1:2 
    keys_zone=shortcache:10m 
    max_size=500m 
    inactive=10m
    use_temp_path=off;

proxy_cache_path /var/cache/nginx/dailycache 
    levels=1:2 
    keys_zone=dailycache:50m 
    max_size=2g 
    inactive=24h
    use_temp_path=off;

upstream flask_backend {
    server 127.0.0.1:9101;
}

server {
    listen 8000;
    server_name mstrws.magdeburger.local;
    
    client_max_body_size 10M;
    
    # Admin routes - bypass cache
    location /admin {
        proxy_pass http://flask_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_no_cache 1;
        proxy_cache_bypass 1;
    }
    
    location /api/admin {
        proxy_pass http://flask_backend;
        proxy_set_header Host $host;
        proxy_no_cache 1;
        proxy_cache_bypass 1;
    }
    
    # Health checks - bypass cache
    location ~ ^/(ping|health) {
        proxy_pass http://flask_backend;
        proxy_no_cache 1;
        proxy_cache_bypass 1;
    }
    
    # v3 API - conditional caching
    location /api/v3 {
        proxy_pass http://flask_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        
        # Cache key includes full request URI and query params
        proxy_cache_key "$request_uri";
        
        # Use dailycache as default (covers most MSTR endpoints)
        # Flask's Cache-Control header controls actual cache duration
        proxy_cache dailycache;
        
        # Bypass cache if Flask sends Cache-Control: no-store (live endpoints)
        proxy_no_cache $upstream_http_cache_control;
        proxy_cache_bypass $upstream_http_cache_control;
        
        # Cache valid responses for up to 24h (overridden by Cache-Control)
        proxy_cache_valid 200 24h;
        
        # Serve stale content if backend is down
        proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
        
        # Add cache status to response
        # HIT = served from cache, MISS = freshly generated, BYPASS = no caching (live endpoints)
        add_header X-Cache-Status $upstream_cache_status always;
        add_header X-Cache-Zone $upstream_http_x_cache_zone always;
        
        # Timeouts for long-running queries
        proxy_read_timeout 300s;
        proxy_connect_timeout 10s;
        
        # Buffer settings
        proxy_buffering on;
        proxy_buffer_size 16k;
        proxy_buffers 8 16k;
    }
}
